"""
æ¨ç†è„šæœ¬ - åŠ è½½è®­ç»ƒå¥½çš„ A3C æ¨¡å‹è¿›è¡Œ Super Mario Bros æ¸¸æˆæ¨ç†
Usage: python inference.py --checkpoint path/to/checkpoint.pt [options]
"""

import argparse
import json
import time
from pathlib import Path
from typing import Optional

import numpy as np
import torch
import torch.nn.functional as F
from torch.distributions import Categorical

from src.config import ModelConfig
from src.envs.mario import MarioEnvConfig, create_vector_env, MarioVectorEnvConfig
from src.models import MarioActorCritic


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="æ¨ç† Super Mario Bros A3C æ¨¡å‹")
    parser.add_argument(
        "--checkpoint", 
        type=str, 
        required=True, 
        help="æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ (.pt)"
    )
    parser.add_argument(
        "--episodes", 
        type=int, 
        default=5, 
        help="æ¨ç† episode æ•°é‡"
    )
    parser.add_argument(
        "--render", 
        action="store_true", 
        help="æ˜¯å¦æ˜¾ç¤ºæ¸¸æˆç”»é¢ï¼ˆéœ€è¦æ˜¾ç¤ºå™¨ï¼‰"
    )
    parser.add_argument(
        "--deterministic", 
        action="store_true", 
        help="ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œï¼‰è€Œéé‡‡æ ·"
    )
    parser.add_argument(
        "--device", 
        type=str, 
        default="auto", 
        choices=["auto", "cpu", "cuda"], 
        help="æ¨ç†è®¾å¤‡"
    )
    parser.add_argument(
        "--seed", 
        type=int, 
        default=42, 
        help="éšæœºç§å­"
    )
    parser.add_argument(
        "--max-steps", 
        type=int, 
        default=10000, 
        help="å•ä¸ª episode æœ€å¤§æ­¥æ•°"
    )
    parser.add_argument(
        "--record-video", 
        action="store_true", 
        help="å½•åˆ¶æ¨ç†è§†é¢‘åˆ° output/inference_videos/"
    )
    parser.add_argument(
        "--verbose", 
        action="store_true", 
        help="è¯¦ç»†è¾“å‡ºæ¯æ­¥ä¿¡æ¯"
    )
    return parser.parse_args()


def load_checkpoint_metadata(checkpoint_path: Path) -> dict:
    """åŠ è½½æ£€æŸ¥ç‚¹çš„å…ƒæ•°æ®é…ç½®"""
    metadata_path = checkpoint_path.with_suffix(".json")
    if not metadata_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶: {metadata_path}")
    
    with open(metadata_path, "r", encoding="utf-8") as f:
        return json.load(f)


def create_inference_env(metadata: dict, render: bool = False, record_video: bool = False):
    """æ ¹æ®æ¨¡å‹å…ƒæ•°æ®åˆ›å»ºæ¨ç†ç¯å¢ƒ"""
    # ä»å…ƒæ•°æ®æ„å»ºç¯å¢ƒé…ç½®
    env_cfg = MarioEnvConfig(
        world=metadata["world"],
        stage=metadata["stage"], 
        action_type=metadata["action_type"],
        frame_skip=metadata["frame_skip"],
        frame_stack=metadata["frame_stack"],
        video_dir="output/inference_videos" if record_video else None,
        record_video=record_video,
    )
    
    # å•ç¯å¢ƒæ¨ç†é…ç½®
    vector_cfg = MarioVectorEnvConfig(
        num_envs=1,
        asynchronous=False,
        stage_schedule=tuple([(metadata["world"], metadata["stage"])]),
        random_start_stage=False,
        base_seed=42,
        env=env_cfg,
    )
    
    return create_vector_env(vector_cfg)


def load_model(checkpoint_path: Path, metadata: dict, device: torch.device) -> MarioActorCritic:
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model_cfg = ModelConfig(**metadata["model"])
    model = MarioActorCritic(model_cfg).to(device)
    
    # åŠ è½½æ£€æŸ¥ç‚¹ - è®¾ç½® weights_only=False ä»¥å…¼å®¹æ—§ç‰ˆæœ¬checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint["model"])
    model.eval()  # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    
    print(f"[inference] æˆåŠŸåŠ è½½æ¨¡å‹: {checkpoint_path}")
    print(f"[inference] æ¨¡å‹é…ç½®: {model_cfg}")
    
    if "global_step" in checkpoint:
        print(f"[inference] è®­ç»ƒæ­¥æ•°: {checkpoint['global_step']}")
    if "global_update" in checkpoint:
        print(f"[inference] è®­ç»ƒè½®æ¬¡: {checkpoint['global_update']}")
    
    return model


def run_inference_episode(
    env, 
    model: MarioActorCritic, 
    device: torch.device, 
    max_steps: int = 10000,
    deterministic: bool = False,
    verbose: bool = False
) -> tuple[float, int, dict]:
    """è¿è¡Œå•ä¸ªæ¨ç† episode"""
    obs_np, info = env.reset()
    obs = torch.as_tensor(obs_np, dtype=torch.float32, device=device)
    
    # åˆå§‹åŒ–éšè—çŠ¶æ€
    hidden_state, cell_state = model.initial_state(1, device)
    
    total_reward = 0.0
    steps = 0
    episode_info = {"x_pos": [], "stage": [], "flag_get": False, "life": 2}
    
    for step in range(max_steps):
        with torch.no_grad():
            output = model(obs, hidden_state, cell_state)
            logits = output.logits
            value = output.value
            
            if deterministic:
                # ç¡®å®šæ€§ç­–ç•¥ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œ
                action = torch.argmax(logits, dim=-1)
            else:
                # éšæœºç­–ç•¥ï¼šæŒ‰æ¦‚ç‡é‡‡æ ·
                dist = Categorical(logits=logits)
                action = dist.sample()
        
        action_np = action.cpu().numpy()
        obs_np, reward_np, terminated, truncated, info_dict = env.step(action_np)
        
        reward = float(reward_np[0])
        total_reward += reward
        steps += 1
        
        # è®°å½•æ¸¸æˆä¿¡æ¯
        if info_dict and len(info_dict) > 0 and "x_pos" in info_dict[0]:
            episode_info["x_pos"].append(info_dict[0]["x_pos"])
            episode_info["stage"].append(info_dict[0].get("stage", 1))
            if info_dict[0].get("flag_get", False):
                episode_info["flag_get"] = True
            episode_info["life"] = info_dict[0].get("life", 2)
        
        if verbose and (step + 1) % 100 == 0:
            action_id = int(action_np[0])
            prob = F.softmax(logits, dim=-1)[0, action_id].item()
            print(f"  æ­¥æ•° {step+1:4d}: åŠ¨ä½œ={action_id:2d} æ¦‚ç‡={prob:.3f} å¥–åŠ±={reward:6.1f} ä»·å€¼={value.item():6.2f}")
        
        # æ›´æ–°è§‚æµ‹å’Œéšè—çŠ¶æ€
        obs = torch.as_tensor(obs_np, dtype=torch.float32, device=device)
        if output.hidden_state is not None:
            hidden_state = output.hidden_state
            if terminated[0] or truncated[0]:
                hidden_state = hidden_state * 0.0  # é‡ç½®éšè—çŠ¶æ€
            if output.cell_state is not None:
                cell_state = output.cell_state
                if terminated[0] or truncated[0]:
                    cell_state = cell_state * 0.0
        
        # æ£€æŸ¥ episode ç»“æŸ
        if terminated[0] or truncated[0]:
            break
    
    return total_reward, steps, episode_info


def main():
    args = parse_args()
    
    # è®¾å¤‡é…ç½®
    if args.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(args.device)
    print(f"[inference] ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # åŠ è½½æ£€æŸ¥ç‚¹å’Œå…ƒæ•°æ®
    checkpoint_path = Path(args.checkpoint)
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    print(f"[inference] åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
    metadata = load_checkpoint_metadata(checkpoint_path)
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"[inference] åˆ›å»ºæ¨ç†ç¯å¢ƒ World {metadata['world']}-{metadata['stage']} ({metadata['action_type']})")
    env = create_inference_env(metadata, render=args.render, record_video=args.record_video)
    
    try:
        # åŠ è½½æ¨¡å‹
        model = load_model(checkpoint_path, metadata, device)
        
        # è¿è¡Œæ¨ç†
        print(f"[inference] å¼€å§‹æ¨ç† {args.episodes} ä¸ª episode...")
        print("=" * 80)
        
        results = []
        total_start_time = time.time()
        
        for episode in range(args.episodes):
            print(f"Episode {episode + 1}/{args.episodes}")
            
            episode_start_time = time.time()
            reward, steps, info = run_inference_episode(
                env, model, device, 
                max_steps=args.max_steps,
                deterministic=args.deterministic,
                verbose=args.verbose
            )
            episode_duration = time.time() - episode_start_time
            
            results.append({
                "episode": episode + 1,
                "reward": reward,
                "steps": steps,
                "duration": episode_duration,
                "flag_get": info["flag_get"],
                "max_x_pos": max(info["x_pos"]) if info["x_pos"] else 0,
                "final_life": info["life"]
            })
            
            status = "ğŸ é€šå…³!" if info["flag_get"] else f"âŒ å¤±è´¥ (æœ€è¿œä½ç½®: {max(info['x_pos']) if info['x_pos'] else 0})"
            print(f"  ç»“æœ: {status}")
            print(f"  å¥–åŠ±: {reward:8.1f} | æ­¥æ•°: {steps:5d} | æ—¶é•¿: {episode_duration:6.2f}s")
            print("-" * 80)
        
        # æ±‡æ€»ç»Ÿè®¡
        total_duration = time.time() - total_start_time
        avg_reward = np.mean([r["reward"] for r in results])
        avg_steps = np.mean([r["steps"] for r in results])
        success_rate = np.mean([r["flag_get"] for r in results]) * 100
        max_reward = max([r["reward"] for r in results])
        
        print(f"\nğŸ“Š æ¨ç†æ±‡æ€»ç»Ÿè®¡:")
        print(f"  æˆåŠŸç‡: {success_rate:5.1f}% ({sum(r['flag_get'] for r in results)}/{args.episodes})")
        print(f"  å¹³å‡å¥–åŠ±: {avg_reward:8.1f} (æœ€é«˜: {max_reward:8.1f})")
        print(f"  å¹³å‡æ­¥æ•°: {avg_steps:8.1f}")
        print(f"  æ€»è€—æ—¶: {total_duration:6.2f}s")
        print(f"  ç­–ç•¥æ¨¡å¼: {'ç¡®å®šæ€§' if args.deterministic else 'éšæœºé‡‡æ ·'}")
        
        if args.record_video:
            print(f"  è§†é¢‘å·²ä¿å­˜è‡³: output/inference_videos/")
            
    finally:
        env.close()
        print("[inference] æ¨ç†å®Œæˆ")


if __name__ == "__main__":
    main()