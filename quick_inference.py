"""
å¿«é€Ÿæ¨ç†è„šæœ¬ - ç›´æ¥è¿è¡ŒæŒ‡å®šæ¨¡å‹
Usage: python quick_inference.py
"""

import torch
import numpy as np
from pathlib import Path
import json
import time

from src.config import ModelConfig
from src.envs.mario import MarioEnvConfig, create_vector_env, MarioVectorEnvConfig
from src.models import MarioActorCritic
from torch.distributions import Categorical


def main():
    # é…ç½®
    checkpoint_path = Path("trained_models/run01/a3c_world1_stage1_0008000.pt")
    metadata_path = checkpoint_path.with_suffix(".json")
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½å…ƒæ•°æ®
    with open(metadata_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)
    
    print(f"åŠ è½½æ¨¡å‹: {checkpoint_path}")
    print(f"World {metadata['world']}-{metadata['stage']} | åŠ¨ä½œç±»å‹: {metadata['action_type']}")
    
    # åˆ›å»ºæ¨¡å‹
    model_cfg = ModelConfig(**metadata["model"])
    model = MarioActorCritic(model_cfg).to(device)
    
    # åŠ è½½æƒé‡ - è®¾ç½® weights_only=False ä»¥å…¼å®¹æ—§ç‰ˆæœ¬checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint["model"])
    model.eval()
    
    print(f"è®­ç»ƒæ­¥æ•°: {checkpoint.get('global_step', 0)}")
    print(f"è®­ç»ƒè½®æ¬¡: {checkpoint.get('global_update', 0)}")
    
    # åˆ›å»ºç¯å¢ƒ
    env_cfg = MarioEnvConfig(
        world=metadata["world"],
        stage=metadata["stage"],
        action_type=metadata["action_type"],
        frame_skip=metadata["frame_skip"],
        frame_stack=metadata["frame_stack"],
    )
    
    vector_cfg = MarioVectorEnvConfig(
        num_envs=1,
        asynchronous=False,
        stage_schedule=tuple([(metadata["world"], metadata["stage"])]),
        random_start_stage=False,
        base_seed=42,
        env=env_cfg,
    )
    
    env = create_vector_env(vector_cfg)
    
    try:
        # è¿è¡Œæ¨ç†
        for episode in range(3):  # è¿è¡Œ3ä¸ªepisode
            print(f"\n=== Episode {episode + 1} ===")
            
            obs_np, info = env.reset()
            obs = torch.as_tensor(obs_np, dtype=torch.float32, device=device)
            
            hidden_state, cell_state = model.initial_state(1, device)
            
            total_reward = 0.0
            steps = 0
            max_x_pos = 0
            
            for step in range(5000):  # æœ€å¤š5000æ­¥
                with torch.no_grad():
                    output = model(obs, hidden_state, cell_state)
                    
                    # ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆé€‰æœ€é«˜æ¦‚ç‡åŠ¨ä½œï¼‰
                    action = torch.argmax(output.logits, dim=-1)
                    
                action_np = action.cpu().numpy()
                obs_np, reward_np, terminated, truncated, info_dict = env.step(action_np)
                
                reward = float(reward_np[0])
                total_reward += reward
                steps += 1
                
                # æ›´æ–°çŠ¶æ€
                obs = torch.as_tensor(obs_np, dtype=torch.float32, device=device)
                if output.hidden_state is not None:
                    hidden_state = output.hidden_state
                    if output.cell_state is not None:
                        cell_state = output.cell_state
                
                # è·å–æ¸¸æˆä¿¡æ¯
                current_x_pos = 0
                if info_dict and len(info_dict) > 0:
                    # info_dictå¯èƒ½æ˜¯listæˆ–dictï¼Œéœ€è¦é€‚é…
                    if isinstance(info_dict, list) and len(info_dict) > 0:
                        game_info = info_dict[0]
                    elif isinstance(info_dict, dict):
                        game_info = info_dict
                    else:
                        game_info = {}
                    
                    current_x_pos = game_info.get("x_pos", current_x_pos)
                    max_x_pos = max(max_x_pos, current_x_pos)
                    
                    # æ¯100æ­¥æ‰“å°ä¸€æ¬¡è¿›åº¦
                    if (step + 1) % 100 == 0:
                        print(f"  æ­¥æ•°: {step+1:4d} | Xä½ç½®: {current_x_pos:4d} | ç´¯è®¡å¥–åŠ±: {total_reward:7.1f}")
                    
                    # æ£€æŸ¥é€šå…³
                    if game_info.get("flag_get", False):
                        print(f"ğŸ é€šå…³æˆåŠŸ! æ­¥æ•°: {steps}, å¥–åŠ±: {total_reward:.1f}")
                        break
                else:
                    # æ²¡æœ‰infoæ—¶çš„è¿›åº¦è¾“å‡º
                    if (step + 1) % 100 == 0:
                        print(f"  æ­¥æ•°: {step+1:4d} | ç´¯è®¡å¥–åŠ±: {total_reward:7.1f}")
                
                if terminated[0] or truncated[0]:
                    print(f"âŒ Episodeç»“æŸ | æœ€è¿œä½ç½®: {max_x_pos} | æ€»å¥–åŠ±: {total_reward:.1f} | æ€»æ­¥æ•°: {steps}")
                    break
            
            time.sleep(1)  # çŸ­æš‚æš‚åœ
    
    finally:
        env.close()
        print("\næ¨ç†å®Œæˆ!")


if __name__ == "__main__":
    main()